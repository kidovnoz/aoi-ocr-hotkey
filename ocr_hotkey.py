import keyboard
import pyautogui
from PIL import ImageGrab, ImageDraw, Image
import pytesseract
import time
from datetime import datetime
import threading
import json
import os
import numpy as np
import csv

REGIONS_FILE = "ocr_regions.json"
regions = []

# N·∫øu c·∫ßn, ch·ªâ ƒë·ªãnh Tesseract path:
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

if os.path.exists(REGIONS_FILE):
    with open(REGIONS_FILE, 'r') as f:
        regions = json.load(f)

showing_coords = False
click_stage = 0
point1 = None

def run_ocr_all():
    if not regions:
        print("‚ö†Ô∏è Ch∆∞a c√≥ v√πng n√†o ƒë·ªÉ OCR!")
        return []

    full_screenshot = ImageGrab.grab()
    img_np = np.array(full_screenshot)
    ocr_results = []

    for i, region in enumerate(regions, start=1):
        x1, y1, x2, y2 = region
        if x2 <= x1 or y2 <= y1:
            print(f"‚ö†Ô∏è B·ªè qua v√πng l·ªói (t·ªça ƒë·ªô sai): {region}")
            continue
        print(f"üïí Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üñºÔ∏è V√πng {i} [{x1}, {y1}, {x2}, {y2}]:")
        cropped_img = img_np[y1:y2, x1:x2]

        # Chuy·ªÉn sang PIL Image RGB (cho pytesseract)
        pil_img = Image.fromarray(cropped_img).convert('RGB')
        text = pytesseract.image_to_string(pil_img, lang='eng').strip()

        if not text:
            print("üì≠ Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c vƒÉn b·∫£n.")
        else:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            print(f"üî§ {text}")
            # log_to_csv(timestamp, i, region, text, 1.0)
            ocr_results.append((i, region, text, timestamp))

        print("-" * 60)
    return ocr_results

def show_mouse_position():
    global showing_coords
    showing_coords = True
    print("\nüìç ƒêang hi·ªÉn th·ªã t·ªça ƒë·ªô chu·ªôt. Nh·∫•n F3 l·∫ßn n·ªØa ƒë·ªÉ d·ª´ng.\n")
    last_pos = (-1, -1)
    while showing_coords:
        x, y = pyautogui.position()
        if (x, y) != last_pos:
            print(f"T·ªça ƒë·ªô hi·ªán t·∫°i: ({x}, {y})", end="\r")
            last_pos = (x, y)
        time.sleep(0.3)
    print("\nüõë ƒê√£ d·ª´ng hi·ªÉn th·ªã t·ªça ƒë·ªô.")

def toggle_show_coords():
    global showing_coords
    if not showing_coords:
        threading.Thread(target=show_mouse_position, daemon=True).start()
    else:
        showing_coords = False

def mark_region():
    global click_stage, point1
    if click_stage == 0:
        point1 = pyautogui.position()
        print(f"üìå ƒêi·ªÉm b·∫Øt ƒë·∫ßu: {point1}")
        click_stage = 1
    else:
        point2 = pyautogui.position()
        print(f"üìå ƒêi·ªÉm k·∫øt th√∫c: {point2}")
        x1, y1 = point1
        x2, y2 = point2
        region = (min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2))
        regions.append(region)
        with open(REGIONS_FILE, 'w') as f:
            json.dump(regions, f)
        print(f"‚úÖ ƒê√£ th√™m v√πng OCR: {region}")
        click_stage = 0

def show_all_regions():
    if not regions:
        print("‚ö†Ô∏è Ch∆∞a c√≥ v√πng n√†o ƒë·ªÉ hi·ªÉn th·ªã!")
        return

    screenshot = ImageGrab.grab()
    draw = ImageDraw.Draw(screenshot)
    for i, (x1, y1, x2, y2) in enumerate(regions, start=1):
        draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
        draw.text((x1 + 5, y1 + 5), f"V{i}", fill="yellow")
    screenshot.show()
def clear_all_regions():
    global regions
    confirm = input("‚ö†Ô∏è B·∫°n c√≥ ch·∫Øc mu·ªën xo√° to√†n b·ªô v√πng OCR? (y/n): ").lower()
    if confirm == 'y':
        regions = []
        if os.path.exists(REGIONS_FILE):
            os.remove(REGIONS_FILE)
        print("üßπ ƒê√£ xo√° to√†n b·ªô v√πng OCR!")
    else:
        print("‚ùé ƒê√£ hu·ª∑ thao t√°c.")

print("\n======================= OCR TOOL (Tesseract) =======================")
print("üü¢ F2: Qu√©t to√†n b·ªô v√πng OCR")
print("üîµ F3: Xem t·ªça ƒë·ªô chu·ªôt")
print("üü° F4: ƒê√°nh d·∫•u 2 ƒëi·ªÉm t·∫°o v√πng OCR")
print("üü£ F5: Hi·ªÉn th·ªã c√°c v√πng OCR")
print("üü† F6: Xo√° to√†n b·ªô v√πng OCR")
print("üî¥ ESC: Tho√°t ch∆∞∆°ng tr√¨nh")
print("====================================================================")

while True:
    if keyboard.is_pressed('f2'):
        ocr_results = run_ocr_all()
        if ocr_results:
            print("üñºÔ∏è ƒê√£ qu√©t xong c√°c v√πng OCR.")
        else:
            print("‚ö†Ô∏è Kh√¥ng c√≥ vƒÉn b·∫£n n√†o ƒë∆∞·ª£c nh·∫≠n di·ªán.")
        time.sleep(0.5)

    elif keyboard.is_pressed('f3'):
        toggle_show_coords()
        time.sleep(0.5)
    elif keyboard.is_pressed('f4'):
        mark_region()
        time.sleep(0.5)
    elif keyboard.is_pressed('f5'):
        show_all_regions()
        time.sleep(0.5)
    elif keyboard.is_pressed('f6'):
        clear_all_regions()
        time.sleep(0.5)
    elif keyboard.is_pressed('esc'):
        print("\nüëã ƒê√£ tho√°t ch∆∞∆°ng tr√¨nh.")
        break
    time.sleep(0.1)
